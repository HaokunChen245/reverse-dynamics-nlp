{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stationary_reversal' from '/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal.py'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import stationary_reversal as sr\n",
    "reload(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "          \"EleutherAI/pythia-70m-deduped-v0\"\n",
    "      ).to(device)\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "prefix_length  = 1\n",
    "suffix = \" Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "# tokenized_suffix = tokenized_suffix.unsqueeze(0)\n",
    "suffix_length = len(tokenized_suffix[0])\n",
    "empirical_dist = torch.load(\"../data/pile10k_empirical.pt\")\n",
    "vocab_size = empirical_dist.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:13<00:00,  2.30s/it]\n",
      "/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal.py:126: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Obama_log_probs_batch = sr.stationary_reverse_full_dist(\n",
    "  model, empirical_dist, prefix_length, tokenized_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_suffix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"afterless/reverse-pythia-160m\"\n",
    ").to(device)\n",
    "reverse_model.eval()\n",
    "rev_out = reverse_model(input_ids=tokenized_suffix)\n",
    "rev_logits = rev_out.logits\n",
    "rev_logprobs = torch.nn.functional.log_softmax(rev_logits, dim=-1)\n",
    "rev_probs = torch.exp(rev_logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Obama_probs = torch.exp(Obama_log_probs_batch)\n",
    "stat_total_variation = 0.5*torch.sum(torch.abs(Obama_probs[0,:] - rev_probs[0,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_dist = (1.0/vocab_size)+torch.zeros(vocab_size)\n",
    "unif_total_variation = 0.5*torch.sum(torch.abs(uniform_dist - rev_probs[0,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stationary_reverse_full_dist_suffix_calculation() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m reload(sr)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tokenized_suffix_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((torch\u001b[39m.\u001b[39mzeros([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint32) ,tokenized_suffix),dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_suffix \u001b[39m=\u001b[39m sr\u001b[39m.\u001b[39;49mstationary_reverse_full_dist_suffix_calculation(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       empirical_dist, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       tokenized_suffix_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal_test.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       batch_size\u001b[39m=\u001b[39;49m\u001b[39m1572\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: stationary_reverse_full_dist_suffix_calculation() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import stationary_reversal as sr\n",
    "reload(sr)\n",
    "\n",
    "tokenized_suffix_test = torch.cat((torch.zeros([1,2], dtype=torch.int32) ,tokenized_suffix),dim=-1)\n",
    "test_suffix = sr.stationary_reverse_full_dist_suffix_calculation(\n",
    "      model,\n",
    "      empirical_dist, \n",
    "      tokenized_suffix_test,\n",
    "      vocab_batch_size=1572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_suffix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*(torch.sum(torch.abs(torch.exp(test_suffix)-Obama_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50304])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_suffix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversing-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
