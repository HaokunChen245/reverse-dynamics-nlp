{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stationary_reversal' from 'c:\\\\Users\\\\abhay\\\\Documents\\\\research\\\\reverse-dynamics-nlp\\\\reverse-llm-benchmarking\\\\stationary_reversal.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import stationary_reversal as sr\n",
    "reload(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-160m-deduped\",\n",
    "    revision=\"step3000\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "reverse_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"afterless/reverse-pythia-160m\"\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_length = 10\n",
    "suffix = \" Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "# tokenized_suffix = tokenized_suffix.unsqueeze(0)\n",
    "suffix_length = len(tokenized_suffix[0])\n",
    "empirical_dist = torch.load(\"..\\data\\pythia-160m-deduped-v0_stationary_dist.pt\").cuda()\n",
    "\n",
    "vocab_size = empirical_dist.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:18<00:00, 21.33it/s]\n",
      "100%|██████████| 393/393 [00:20<00:00, 19.16it/s]\n",
      "100%|██████████| 393/393 [00:27<00:00, 14.46it/s]\n",
      "100%|██████████| 393/393 [00:32<00:00, 12.13it/s]\n",
      "100%|██████████| 393/393 [00:36<00:00, 10.82it/s]\n",
      "100%|██████████| 393/393 [00:41<00:00,  9.38it/s]\n",
      "100%|██████████| 393/393 [00:45<00:00,  8.64it/s]\n",
      "100%|██████████| 393/393 [00:33<00:00, 11.67it/s]\n",
      "100%|██████████| 393/393 [00:34<00:00, 11.53it/s]\n",
      "100%|██████████| 393/393 [01:04<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import sample_reverse_dynamics_reverse_prior\n",
    "\n",
    "output1, logits1 = sample_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    prefix_length,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The former vice president also said that former President Barack Obama'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/393 [00:00<00:19, 19.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:19<00:00, 19.91it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 23.01it/s]\n",
      "100%|██████████| 393/393 [00:13<00:00, 28.67it/s]\n",
      "100%|██████████| 393/393 [00:20<00:00, 19.60it/s]\n",
      "100%|██████████| 393/393 [00:21<00:00, 18.03it/s]\n",
      "100%|██████████| 393/393 [00:21<00:00, 18.08it/s]\n",
      "100%|██████████| 393/393 [00:22<00:00, 17.65it/s]\n",
      "100%|██████████| 393/393 [00:33<00:00, 11.89it/s]\n",
      "100%|██████████| 393/393 [00:28<00:00, 13.72it/s]\n",
      "100%|██████████| 393/393 [00:54<00:00,  7.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8440284729003906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reverse_sampling import compute_loss_reverse_dynamics_reverse_prior\n",
    "\n",
    "\n",
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverse_sampling import compute_loss_reverse_dynamics\n",
    "\n",
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = compute_loss_reverse_dynamics(\n",
    "    model,\n",
    "    empirical_dist,\n",
    "    tokenized_suffix,\n",
    "    dilution=1.0,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Posterior vs Stationary Reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_dist = torch.ones_like(empirical_dist) / empirical_dist.shape[0]\n",
    "empirical_dist = empirical_dist * 0.7 + uniform_dist * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:13<00:00,  7.47it/s]\n",
      "100%|██████████| 99/99 [00:14<00:00,  7.02it/s]\n",
      "100%|██████████| 99/99 [00:17<00:00,  5.76it/s]\n",
      "100%|██████████| 99/99 [00:18<00:00,  5.39it/s]\n",
      "100%|██████████| 99/99 [00:24<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import sample_reverse_dynamics\n",
    "\n",
    "output1, logits1 = sample_reverse_dynamics(\n",
    "    model,\n",
    "    empirical_dist,\n",
    "    prefix_length,\n",
    "    tokenized_suffix,\n",
    "    temperature=0.7,\n",
    "    vocab_batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In thiserior pair, Obama'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "logits2 = sr.stationary_reverse_full_dist_suffix_calculation(model, empirical_dist, output1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-14.1750, -14.4474, -15.0450,  ..., -13.0240, -12.8964, -13.3337],\n",
       "        [-12.3171, -12.7534, -13.0377,  ..., -12.1253,  -9.1679, -14.2333],\n",
       "        [-13.4286, -12.3321, -11.0569,  ..., -10.6190, -11.5005, -12.7546],\n",
       "        [-11.3032, -11.4353, -13.2914,  ..., -12.1252, -11.5411, -13.5619],\n",
       "        [-13.5377, -15.0662,  -8.3655,  ..., -14.6411, -13.6813, -13.2714]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits1.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0518e-05, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(logits2 - logits1.log_softmax(dim=-1)).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversing-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
