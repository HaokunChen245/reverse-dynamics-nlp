{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXTokenizerFast\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='EleutherAI/gpt-neox-20b', vocab_size=50254, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_chunked_dataset_from_full_sequences' from 'utils' (/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/explore_pile.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/explore_pile.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/explore_pile.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m GPTNeoXForCausalLM, GPTNeoXTokenizerFast, DataCollatorForLanguageModeling\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/explore_pile.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_dataset, create_chunked_dataset_from_full_sequences\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_chunked_dataset_from_full_sequences' from 'utils' (/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/utils.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast, DataCollatorForLanguageModeling\n",
    "from utils import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/alexinf/Dropbox/github/reverse-dynamics-nlp/reverse_llm_benchmarking/utils.py'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils as u\n",
    "reload(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = u.create_chunked_dataset_from_full_sequences(\n",
    "        \"DebugDataSet\",\n",
    "        tokenizer,\n",
    "        1,\n",
    "        2,\n",
    "        batch_size=1,\n",
    "        seed=42,\n",
    "        return_all = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :   President Donald Trump\n",
      "torch.Size([1, 3])\n",
      "1  :   filed a lawsuit\n",
      "torch.Size([1, 3])\n",
      "2  :   against former President\n",
      "torch.Size([1, 3])\n",
      "3  :   Barack Obama\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "for (i,batch) in enumerate(test_dataset):  \n",
    "  print(i, \" : \", tokenizer.decode(batch['input_ids'][0]))\n",
    "  print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = u.create_dataset(\n",
    "    \"pile_val\",\n",
    "    tokenizer,\n",
    "    10,\n",
    "    49,\n",
    "    suffix_length=1,\n",
    "    num_buffer=0,\n",
    "    suffix_batch_size=1,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 20\n",
    "dataset = load_dataset('json', data_files='data/val.jsonl')\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset['train'].select(range(num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20/20 [00:00<00:00, 476.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(lambda data: {\n",
    "    'input_ids': tokenizer.encode(\n",
    "        data['text'],\n",
    "        return_tensors='pt'\n",
    "    ).squeeze(0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20/20 [00:00<00:00, 1874.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.map(lambda x: {'num_tokens': len(x['input_ids'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[326,\n",
       " 1025,\n",
       " 118,\n",
       " 144,\n",
       " 80,\n",
       " 309,\n",
       " 802,\n",
       " 67,\n",
       " 146,\n",
       " 977,\n",
       " 91,\n",
       " 211,\n",
       " 614,\n",
       " 657,\n",
       " 694,\n",
       " 177,\n",
       " 99,\n",
       " 148,\n",
       " 527,\n",
       " 352]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_length = 10\n",
    "suffix = \" Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "# tokenized_suffix = tokenized_suffix.unsqueeze(0)\n",
    "suffix_length = len(tokenized_suffix[0])\n",
    "empirical_dist = torch.load(\"..\\data\\pythia-160m-deduped-v0_stationary_dist.pt\").cuda()\n",
    "\n",
    "vocab_size = empirical_dist.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:18<00:00, 21.33it/s]\n",
      "100%|██████████| 393/393 [00:20<00:00, 19.16it/s]\n",
      "100%|██████████| 393/393 [00:27<00:00, 14.46it/s]\n",
      "100%|██████████| 393/393 [00:32<00:00, 12.13it/s]\n",
      "100%|██████████| 393/393 [00:36<00:00, 10.82it/s]\n",
      "100%|██████████| 393/393 [00:41<00:00,  9.38it/s]\n",
      "100%|██████████| 393/393 [00:45<00:00,  8.64it/s]\n",
      "100%|██████████| 393/393 [00:33<00:00, 11.67it/s]\n",
      "100%|██████████| 393/393 [00:34<00:00, 11.53it/s]\n",
      "100%|██████████| 393/393 [01:04<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import sample_reverse_dynamics_reverse_prior\n",
    "\n",
    "output1, logits1 = sample_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    prefix_length,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = torch.load(\"../data/distributions/probs_10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e-16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors[priors==0] = 1e-16\n",
    "priors = priors/priors.sum(dim=0)\n",
    "torch.min(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:05<00:00, 68.60it/s]\n",
      "100%|██████████| 393/393 [00:06<00:00, 61.18it/s]\n",
      "100%|██████████| 393/393 [00:07<00:00, 51.69it/s]\n",
      "100%|██████████| 393/393 [00:09<00:00, 43.36it/s]\n",
      "100%|██████████| 393/393 [00:09<00:00, 39.93it/s]\n",
      "100%|██████████| 393/393 [00:11<00:00, 35.14it/s]\n",
      "100%|██████████| 393/393 [00:12<00:00, 32.44it/s]\n",
      "100%|██████████| 393/393 [00:13<00:00, 28.79it/s]\n",
      "100%|██████████| 393/393 [00:14<00:00, 26.35it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 24.39it/s]\n"
     ]
    }
   ],
   "source": [
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = rs.compute_loss_reverse_dynamics(\n",
    "    model,\n",
    "    priors,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.131247520446777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'reverse_sampling' from '/home/adi224/reverse-dynamics-nlp/reverse-llm-benchmarking/reverse_sampling.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import reverse_sampling as rs\n",
    "reload(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.13it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  6.93it/s]\n",
      "100%|██████████| 26/26 [00:04<00:00,  5.20it/s]\n",
      "100%|██████████| 26/26 [00:06<00:00,  4.12it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:08<00:00,  2.91it/s]\n",
      "100%|██████████| 26/26 [00:10<00:00,  2.60it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.29it/s]\n",
      "100%|██████████| 26/26 [00:13<00:00,  2.00it/s]\n",
      "100%|██████████| 26/26 [00:14<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.108232021331787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "suffix = \" Hi, my name is Alex. What's up?\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = rs.compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=2000,\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:16<00:00,  5.98it/s]\n",
      "100%|██████████| 101/101 [00:24<00:00,  4.12it/s]\n",
      "100%|██████████| 101/101 [00:33<00:00,  3.00it/s]\n",
      "100%|██████████| 101/101 [00:41<00:00,  2.44it/s]\n",
      "100%|██████████| 101/101 [00:50<00:00,  2.02it/s]\n",
      "100%|██████████| 101/101 [00:58<00:00,  1.73it/s]\n",
      "100%|██████████| 101/101 [01:07<00:00,  1.49it/s]\n",
      "100%|██████████| 101/101 [01:13<00:00,  1.37it/s]\n",
      "100%|██████████| 101/101 [01:22<00:00,  1.23it/s]\n",
      "100%|██████████| 101/101 [01:29<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.162289619445801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_1B = rs.compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model_1B,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=500,\n",
    ")\n",
    "print(loss_1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \" Hi, my name is Alex. What's up?\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = rs.compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=2000,\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7155, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reversed_suffix = torch.flip(tokenized_suffix, dims=[1])\n",
    "\n",
    "reverse_model.eval()\n",
    "reverse_logits = reverse_model(reversed_suffix[:,:-1]).logits\n",
    "reverse_loss = torch.nn.CrossEntropyLoss()(reverse_logits[0,:,:], reversed_suffix[0, 1:])\n",
    "print(reverse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8015, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "forward_logits = model(tokenized_suffix[:,:-1]).logits\n",
    "forward_loss = torch.nn.CrossEntropyLoss()(forward_logits[0,:,:], tokenized_suffix[0, 1:])\n",
    "print(forward_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.780669689178467"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:06<00:00, 63.79it/s]\n",
      "100%|██████████| 393/393 [00:06<00:00, 58.02it/s]\n",
      "100%|██████████| 393/393 [00:07<00:00, 49.29it/s]\n",
      "100%|██████████| 393/393 [00:09<00:00, 41.78it/s]\n",
      "100%|██████████| 393/393 [00:10<00:00, 38.85it/s]\n",
      "100%|██████████| 393/393 [00:11<00:00, 34.12it/s]\n",
      "100%|██████████| 393/393 [00:12<00:00, 31.49it/s]\n",
      "100%|██████████| 393/393 [00:13<00:00, 28.16it/s]\n",
      "100%|██████████| 393/393 [00:15<00:00, 25.84it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import compute_loss_reverse_dynamics_reverse_prior\n",
    "\n",
    "\n",
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440132141113281\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3918, 10053,  3778,  4724,   247, 15091,  1411,  3438,  3918, 22306,\n",
       "          6729]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing loss:   0%|          | 0/1 [00:00<?, ?it/s]You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3918, 10053,  3778,  4724,   247, 15091,  1411,  3438,  3918, 22306,\n",
      "          6729]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:01,  4.87it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:01,  3.80it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:00<00:01,  3.52it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:01,  3.40it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:01<00:00,  3.33it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:01<00:00,  3.30it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:02<00:00,  3.28it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.37it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:02,  2.56it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  2.37it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:01,  2.29it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  2.25it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:02<00:00,  2.22it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:02,  2.46it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.91it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  1.77it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.71it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  1.68it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:03<00:01,  1.66it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:04<00:00,  1.65it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  1.95it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.51it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.36it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.33it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.32it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.31it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.35it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:08,  1.20s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:05,  1.13it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.11it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.10it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.09it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:05<00:01,  1.09it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:06<00:00,  1.09it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:04,  1.41it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:05,  1.10it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.02it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:03<00:04,  1.02s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:03,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:06<00:02,  1.05s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:07<00:01,  1.06s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:10,  1.44s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:02<00:07,  1.28s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:03<00:06,  1.26s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:05<00:04,  1.25s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:06<00:03,  1.24s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:07<00:02,  1.24s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:08<00:01,  1.24s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:10,  1.46s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:02<00:08,  1.38s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:04<00:06,  1.39s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:05<00:05,  1.40s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:07<00:04,  1.40s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:08<00:02,  1.40s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:09<00:01,  1.41s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:11<00:00,  1.41s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:11,  1.62s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:03<00:09,  1.54s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:04<00:07,  1.55s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:06<00:06,  1.56s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:07<00:04,  1.56s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:09<00:03,  1.57s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:10<00:01,  1.57s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:12<00:00,  1.57s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:02<00:17,  2.53s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:03<00:10,  1.77s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:05<00:08,  1.76s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:07<00:07,  1.76s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:09<00:05,  1.75s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:10<00:03,  1.76s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:12<00:01,  1.76s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:14<00:00,  1.79s/it]\u001b[A\n",
      "Computing loss: 100%|██████████| 1/1 [01:23<00:00, 83.94s/it]\n"
     ]
    }
   ],
   "source": [
    "%run stationary_reversal_loss.py --num_examples 1 --vocab_batch_size 6288 --reverse_model_prior true --prefix_length 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverse_sampling import compute_loss_reverse_dynamics\n",
    "\n",
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = compute_loss_reverse_dynamics(\n",
    "    model,\n",
    "    empirical_dist,\n",
    "    tokenized_suffix,\n",
    "    dilution=1.0,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dateset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Posterior vs Stationary Reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_dist = torch.ones_like(empirical_dist) / empirical_dist.shape[0]\n",
    "empirical_dist = empirical_dist * 0.7 + uniform_dist * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:13<00:00,  7.47it/s]\n",
      "100%|██████████| 99/99 [00:14<00:00,  7.02it/s]\n",
      "100%|██████████| 99/99 [00:17<00:00,  5.76it/s]\n",
      "100%|██████████| 99/99 [00:18<00:00,  5.39it/s]\n",
      "100%|██████████| 99/99 [00:24<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import sample_reverse_dynamics\n",
    "\n",
    "output1, logits1 = sample_reverse_dynamics(\n",
    "    model,\n",
    "    empirical_dist,\n",
    "    prefix_length,\n",
    "    tokenized_suffix,\n",
    "    temperature=0.7,\n",
    "    vocab_batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In thiserior pair, Obama'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "logits2 = sr.stationary_reverse_full_dist_suffix_calculation(model, empirical_dist, output1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-14.1750, -14.4474, -15.0450,  ..., -13.0240, -12.8964, -13.3337],\n",
       "        [-12.3171, -12.7534, -13.0377,  ..., -12.1253,  -9.1679, -14.2333],\n",
       "        [-13.4286, -12.3321, -11.0569,  ..., -10.6190, -11.5005, -12.7546],\n",
       "        [-11.3032, -11.4353, -13.2914,  ..., -12.1252, -11.5411, -13.5619],\n",
       "        [-13.5377, -15.0662,  -8.3655,  ..., -14.6411, -13.6813, -13.2714]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits1.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0518e-05, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(logits2 - logits1.log_softmax(dim=-1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Step 1: Create an empty list to hold all JSON objects.\n",
    "all_data = []\n",
    "\n",
    "# Step 2: Loop through each JSON file in the directory where your files are stored.\n",
    "for filename in glob.glob('data/pile_val/*.json'):\n",
    "    with open(filename, 'r') as file:\n",
    "        # Read the single line of JSON and parse it.\n",
    "        json_data = json.loads(file.readline())\n",
    "        # Append the dictionary to the list.\n",
    "        all_data.append(json_data)\n",
    "\n",
    "# Step 3: Write the list of dictionaries to a new JSON file.\n",
    "with open('combined_data.json', 'w') as outfile:\n",
    "    json.dump(all_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mean': 5.902055968046188,\n",
       "  'variance': 2.9243932490525784,\n",
       "  'std_on_mean': 0.17100857431873345,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.2},\n",
       " {'mean': 3.7944451820850373,\n",
       "  'variance': 1.3930675834793667,\n",
       "  'std_on_mean': 0.11802828404578991,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 5.567424488067627,\n",
       "  'variance': 2.3046989259260138,\n",
       "  'std_on_mean': 0.48007279926340474,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '410m'},\n",
       " {'mean': 5.881934969425202,\n",
       "  'variance': 1.3117366918483122,\n",
       "  'std_on_mean': 0.11453107403007763,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 10,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 6.125863807201386,\n",
       "  'variance': 2.801961312589026,\n",
       "  'std_on_mean': 0.16739060047054694,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.4,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.921818646192551,\n",
       "  'variance': 2.9528719554662475,\n",
       "  'std_on_mean': 0.1718392258905471,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.2},\n",
       " {'mean': 7.409825747013092,\n",
       "  'variance': 3.1201337286434265,\n",
       "  'std_on_mean': 0.17663900273278907,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/smoothed_probs_10.pt',\n",
       "  'dilution': 0.4,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 5.8470072746276855,\n",
       "  'variance': 1.3201813358728953,\n",
       "  'std_on_mean': 0.11489914429067324,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 10,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 4.68057701587677,\n",
       "  'variance': 1.8708533668834602,\n",
       "  'std_on_mean': 0.4325336249222088,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'device': 'cuda',\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.953478407859802,\n",
       "  'variance': 2.245164438493409,\n",
       "  'std_on_mean': 0.14983872792083525,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 20,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 5.987042251825333,\n",
       "  'variance': 2.863637291320495,\n",
       "  'std_on_mean': 0.16922284985546412,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.4},\n",
       " {'mean': 5.870876908302307,\n",
       "  'variance': 2.0224048625667734,\n",
       "  'std_on_mean': 0.4497115589538224,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.7,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 6.376853818893433,\n",
       "  'variance': 2.706090528548768,\n",
       "  'std_on_mean': 0.1645019917371449,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.2,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.905772322416306,\n",
       "  'variance': 3.0646604159031265,\n",
       "  'std_on_mean': 0.17506171528644196,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 1.0,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.46494608104229,\n",
       "  'variance': 3.8171891995005636,\n",
       "  'std_on_mean': 0.19537628309241026,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.2,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 2.829386532180011,\n",
       "  'variance': 0.8332415371077588,\n",
       "  'std_on_mean': 0.028865923458426875,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 8.03367482662201,\n",
       "  'variance': 1.9618762068543893,\n",
       "  'std_on_mean': 0.14006699135964867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.905772310495377,\n",
       "  'variance': 3.064660453937176,\n",
       "  'std_on_mean': 0.17506171637274598,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 6.395029375553131,\n",
       "  'variance': 2.729653022433814,\n",
       "  'std_on_mean': 0.16521661606611526,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.2,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.431550749838352,\n",
       "  'variance': 3.427383108671701,\n",
       "  'std_on_mean': 0.1851319288688934,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.2,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 5.5422512179613115,\n",
       "  'variance': 3.3802772878781746,\n",
       "  'std_on_mean': 0.18385530418995735,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.4,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 3.0134240704774857,\n",
       "  'variance': 0.816403671182231,\n",
       "  'std_on_mean': 0.09035505913794926,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 2.6161921471357346,\n",
       "  'variance': 0.7757284637416746,\n",
       "  'std_on_mean': 0.0880754485507553,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 8.033674807548524,\n",
       "  'variance': 1.9618761721335463,\n",
       "  'std_on_mean': 0.14006699012021162,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 1.0},\n",
       " {'mean': 3.2168437704145907,\n",
       "  'variance': 0.8049592230600622,\n",
       "  'std_on_mean': 0.02837180330997771,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000},\n",
       " {'mean': 5.96704402923584,\n",
       "  'variance': 2.3225680815739924,\n",
       "  'std_on_mean': 0.15239974020889907,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 20,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 3.130835123077035,\n",
       "  'variance': 0.8737931690029227,\n",
       "  'std_on_mean': 0.029559992709791434,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 6.144345463514328,\n",
       "  'variance': 2.826969204275754,\n",
       "  'std_on_mean': 0.16813593322891315,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.4,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 8.03367482662201,\n",
       "  'variance': 1.9618762068543893,\n",
       "  'std_on_mean': 0.14006699135964867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.403787612915039,\n",
       "  'variance': 0.030588694848120213,\n",
       "  'std_on_mean': 0.12367031747375805,\n",
       "  'nbatches': 2,\n",
       "  'num_examples': 2,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 262,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.0,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 4.217538380622864,\n",
       "  'variance': 1.5683602068174818,\n",
       "  'std_on_mean': 0.3960252778317922,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'device': 'cuda',\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 2.3592866617441177,\n",
       "  'variance': 0.7557623486585087,\n",
       "  'std_on_mean': 0.08693459315246772,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 3.648958516120911,\n",
       "  'variance': 1.3038870586557783,\n",
       "  'std_on_mean': 0.3610937632604277,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'device': 'cuda',\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 3.216844655483961,\n",
       "  'variance': 0.8049589379035442,\n",
       "  'std_on_mean': 0.02837179828462666,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 5.923955225944519,\n",
       "  'variance': 2.007545950700597,\n",
       "  'std_on_mean': 0.4480564641538605,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.3657335215806965,\n",
       "  'variance': 3.5412856185113912,\n",
       "  'std_on_mean': 0.1881830390473964,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.0,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 6.005882073640823,\n",
       "  'variance': 2.889953721230947,\n",
       "  'std_on_mean': 0.16999863885428457,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.4},\n",
       " {'mean': 8.130361356735229,\n",
       "  'variance': 4.879760712015729,\n",
       "  'std_on_mean': 0.2209018042483069,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/smoothed_probs_10.pt',\n",
       "  'dilution': 0.0,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 3.5711511905044317,\n",
       "  'variance': 0.9340061170230513,\n",
       "  'std_on_mean': 0.03056151365726265,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000},\n",
       " {'mean': 5.8470072746276855,\n",
       "  'variance': 1.3201813358728953,\n",
       "  'std_on_mean': 0.11489914429067324,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 10,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 8.03367482662201,\n",
       "  'variance': 1.9618762068543893,\n",
       "  'std_on_mean': 0.14006699135964867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 8.155158948898315,\n",
       "  'variance': 0.4123599850644246,\n",
       "  'std_on_mean': 0.20306648789606435,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 1.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 7.525179170370102,\n",
       "  'variance': 3.516449845944826,\n",
       "  'std_on_mean': 0.18752199460182867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/smoothed_probs_10.pt',\n",
       "  'dilution': 0.2,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 5.883956278562546,\n",
       "  'variance': 3.038872731345512,\n",
       "  'std_on_mean': 0.17432362809858887,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 3.571150739625096,\n",
       "  'variance': 0.9340061847834702,\n",
       "  'std_on_mean': 0.030561514765853316,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 5.454675911068916,\n",
       "  'variance': 3.979176864335709,\n",
       "  'std_on_mean': 0.19947874233450816,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.4,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 2.829386526942253,\n",
       "  'variance': 0.8332412405481479,\n",
       "  'std_on_mean': 0.028865918321580347,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000},\n",
       " {'mean': 3.130835074454546,\n",
       "  'variance': 0.8737934575557981,\n",
       "  'std_on_mean': 0.02955999759059189,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reversing-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
