{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoXTokenizerFast\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='EleutherAI/gpt-neox-20b', vocab_size=50254, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast, DataCollatorForLanguageModeling\n",
    "from utils import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stationary_reversal' from '/home/adi224/reverse-dynamics-nlp/reverse-llm-benchmarking/stationary_reversal.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import stationary_reversal as sr\n",
    "reload(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  gets  13\n",
      "[4, 5]  gets  12\n",
      "[3, 4, 5]  gets  11\n",
      "[2, 3, 4, 5]  gets  10\n"
     ]
    }
   ],
   "source": [
    "test = [1,2,3,4,5]\n",
    "dist = [10, 11, 12,13]\n",
    "suffix_length = len(test)\n",
    "for i in reversed(range(1,suffix_length)):\n",
    "    print(test[i:], \" gets \", dist[i-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-160m-deduped\",\n",
    "    revision=\"step3000\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "reverse_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"afterless/reverse-pythia-160m\"\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading pytorch_model.bin:   0%|          | 0.00/2.09G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   1%|          | 21.0M/2.09G [00:00<00:14, 143MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   2%|▏         | 41.9M/2.09G [00:00<00:17, 114MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   3%|▎         | 62.9M/2.09G [00:00<00:18, 107MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   4%|▍         | 83.9M/2.09G [00:00<00:19, 104MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   5%|▌         | 105M/2.09G [00:00<00:19, 103MB/s] \u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   6%|▌         | 115M/2.09G [00:01<00:19, 102MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   6%|▌         | 126M/2.09G [00:01<00:19, 102MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   7%|▋         | 136M/2.09G [00:01<00:30, 64.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   8%|▊         | 157M/2.09G [00:02<00:38, 50.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:   9%|▉         | 189M/2.09G [00:02<00:26, 72.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  10%|▉         | 199M/2.09G [00:02<00:28, 66.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  11%|█         | 220M/2.09G [00:02<00:22, 81.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  12%|█▏        | 252M/2.09G [00:02<00:16, 112MB/s] \u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  13%|█▎        | 273M/2.09G [00:03<00:18, 97.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  14%|█▍        | 294M/2.09G [00:03<00:17, 102MB/s] \u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  15%|█▌        | 315M/2.09G [00:03<00:17, 99.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  16%|█▌        | 336M/2.09G [00:03<00:15, 112MB/s] \u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  17%|█▋        | 357M/2.09G [00:03<00:18, 94.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  18%|█▊        | 377M/2.09G [00:04<00:22, 76.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  19%|█▉        | 398M/2.09G [00:04<00:25, 67.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  20%|██        | 419M/2.09G [00:04<00:22, 74.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  21%|██        | 440M/2.09G [00:05<00:19, 86.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  22%|██▏       | 451M/2.09G [00:05<00:18, 88.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  23%|██▎       | 472M/2.09G [00:05<00:16, 97.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  24%|██▎       | 493M/2.09G [00:05<00:16, 98.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  24%|██▍       | 503M/2.09G [00:06<00:30, 51.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  25%|██▌       | 524M/2.09G [00:06<00:28, 55.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  26%|██▌       | 545M/2.09G [00:06<00:23, 65.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  27%|██▋       | 556M/2.09G [00:07<00:27, 56.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  27%|██▋       | 566M/2.09G [00:07<00:26, 58.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  28%|██▊       | 577M/2.09G [00:07<00:24, 62.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  29%|██▊       | 598M/2.09G [00:07<00:21, 69.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  29%|██▉       | 608M/2.09G [00:07<00:23, 64.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  30%|██▉       | 619M/2.09G [00:08<00:28, 52.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  30%|███       | 629M/2.09G [00:08<00:40, 36.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  32%|███▏      | 661M/2.09G [00:09<00:30, 47.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  33%|███▎      | 682M/2.09G [00:09<00:26, 53.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  33%|███▎      | 692M/2.09G [00:09<00:24, 57.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  34%|███▎      | 703M/2.09G [00:09<00:21, 63.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  34%|███▍      | 713M/2.09G [00:10<00:47, 28.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  35%|███▍      | 724M/2.09G [00:11<00:53, 25.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  35%|███▌      | 734M/2.09G [00:11<00:52, 26.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  36%|███▌      | 744M/2.09G [00:11<00:41, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  37%|███▋      | 765M/2.09G [00:12<00:40, 32.9MB/s]\u001b[A\u001b[A\n",
      "Downloading pytorch_model.bin:  33%|███▎      | 682M/2.09G [00:33<00:55, 25.2MB/s]\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  37%|███▋      | 776M/2.09G [00:12<00:44, 29.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  38%|███▊      | 786M/2.09G [00:13<00:53, 24.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  38%|███▊      | 797M/2.09G [00:13<00:43, 29.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  39%|███▊      | 807M/2.09G [00:13<00:35, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  39%|███▉      | 818M/2.09G [00:14<00:40, 31.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  40%|███▉      | 828M/2.09G [00:14<00:32, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  40%|████      | 839M/2.09G [00:14<00:41, 30.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  41%|████      | 849M/2.09G [00:14<00:33, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  41%|████      | 860M/2.09G [00:15<00:27, 44.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  42%|████▏     | 870M/2.09G [00:15<00:39, 31.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  42%|████▏     | 881M/2.09G [00:15<00:32, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  43%|████▎     | 891M/2.09G [00:16<00:41, 28.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  43%|████▎     | 902M/2.09G [00:16<00:35, 33.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  44%|████▎     | 912M/2.09G [00:16<00:31, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  44%|████▍     | 923M/2.09G [00:17<00:38, 30.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  45%|████▍     | 933M/2.09G [00:17<00:41, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  45%|████▌     | 944M/2.09G [00:18<00:47, 24.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  46%|████▌     | 954M/2.09G [00:18<00:37, 30.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  46%|████▌     | 965M/2.09G [00:18<00:29, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  47%|████▋     | 975M/2.09G [00:19<00:49, 22.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  48%|████▊     | 996M/2.09G [00:20<00:48, 22.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  48%|████▊     | 1.01G/2.09G [00:20<00:39, 27.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  49%|████▉     | 1.03G/2.09G [00:21<00:35, 30.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  50%|████▉     | 1.04G/2.09G [00:21<00:32, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  50%|█████     | 1.05G/2.09G [00:22<00:50, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  51%|█████     | 1.06G/2.09G [00:22<00:41, 24.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  51%|█████     | 1.07G/2.09G [00:22<00:36, 28.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  52%|█████▏    | 1.08G/2.09G [00:23<00:44, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  52%|█████▏    | 1.09G/2.09G [00:23<00:37, 26.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  53%|█████▎    | 1.10G/2.09G [00:24<00:41, 24.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  53%|█████▎    | 1.11G/2.09G [00:24<00:33, 29.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  54%|█████▎    | 1.12G/2.09G [00:24<00:27, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  54%|█████▍    | 1.13G/2.09G [00:25<00:33, 28.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  55%|█████▍    | 1.14G/2.09G [00:25<00:27, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  55%|█████▌    | 1.15G/2.09G [00:25<00:36, 25.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  56%|█████▌    | 1.17G/2.09G [00:26<00:24, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  57%|█████▋    | 1.18G/2.09G [00:26<00:31, 28.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  58%|█████▊    | 1.21G/2.09G [00:27<00:26, 33.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  59%|█████▉    | 1.24G/2.09G [00:28<00:26, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  60%|██████    | 1.26G/2.09G [00:28<00:23, 35.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  61%|██████    | 1.27G/2.09G [00:29<00:22, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  62%|██████▏   | 1.29G/2.09G [00:29<00:21, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  63%|██████▎   | 1.31G/2.09G [00:29<00:19, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  63%|██████▎   | 1.32G/2.09G [00:30<00:17, 43.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  64%|██████▍   | 1.34G/2.09G [00:30<00:18, 40.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  65%|██████▍   | 1.35G/2.09G [00:31<00:20, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  65%|██████▌   | 1.36G/2.09G [00:31<00:22, 31.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  66%|██████▌   | 1.37G/2.09G [00:31<00:19, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  67%|██████▋   | 1.39G/2.09G [00:32<00:20, 34.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  67%|██████▋   | 1.41G/2.09G [00:32<00:17, 38.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  68%|██████▊   | 1.42G/2.09G [00:33<00:21, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  69%|██████▊   | 1.44G/2.09G [00:33<00:16, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  69%|██████▉   | 1.45G/2.09G [00:34<00:24, 25.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  70%|██████▉   | 1.46G/2.09G [00:34<00:21, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  70%|███████   | 1.47G/2.09G [00:34<00:20, 29.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  71%|███████   | 1.49G/2.09G [00:35<00:15, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  72%|███████▏  | 1.50G/2.09G [00:35<00:18, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  72%|███████▏  | 1.51G/2.09G [00:35<00:16, 35.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  73%|███████▎  | 1.52G/2.09G [00:36<00:18, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  74%|███████▎  | 1.54G/2.09G [00:36<00:11, 48.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  74%|███████▍  | 1.55G/2.09G [00:37<00:17, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  75%|███████▌  | 1.57G/2.09G [00:37<00:15, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  76%|███████▌  | 1.59G/2.09G [00:38<00:12, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  77%|███████▋  | 1.60G/2.09G [00:38<00:14, 32.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  77%|███████▋  | 1.61G/2.09G [00:38<00:14, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  78%|███████▊  | 1.63G/2.09G [00:39<00:15, 29.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  78%|███████▊  | 1.64G/2.09G [00:39<00:14, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  79%|███████▊  | 1.65G/2.09G [00:39<00:11, 38.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  79%|███████▉  | 1.66G/2.09G [00:40<00:15, 28.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  80%|███████▉  | 1.67G/2.09G [00:40<00:13, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  80%|████████  | 1.68G/2.09G [00:41<00:17, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  81%|████████  | 1.69G/2.09G [00:41<00:14, 26.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  82%|████████▏ | 1.71G/2.09G [00:42<00:10, 35.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  83%|████████▎ | 1.73G/2.09G [00:42<00:10, 34.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  84%|████████▍ | 1.75G/2.09G [00:43<00:08, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  84%|████████▍ | 1.76G/2.09G [00:43<00:10, 31.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  85%|████████▌ | 1.78G/2.09G [00:44<00:09, 33.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  86%|████████▋ | 1.80G/2.09G [00:44<00:06, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  87%|████████▋ | 1.81G/2.09G [00:45<00:08, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  87%|████████▋ | 1.82G/2.09G [00:45<00:07, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  88%|████████▊ | 1.84G/2.09G [00:45<00:08, 30.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  89%|████████▉ | 1.86G/2.09G [00:46<00:06, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  89%|████████▉ | 1.87G/2.09G [00:46<00:06, 32.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  90%|█████████ | 1.89G/2.09G [00:47<00:06, 33.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  91%|█████████ | 1.90G/2.09G [00:47<00:04, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  91%|█████████▏| 1.91G/2.09G [00:47<00:04, 44.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  92%|█████████▏| 1.92G/2.09G [00:48<00:05, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  92%|█████████▏| 1.93G/2.09G [00:48<00:04, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  93%|█████████▎| 1.94G/2.09G [00:48<00:04, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  93%|█████████▎| 1.95G/2.09G [00:48<00:04, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  94%|█████████▍| 1.96G/2.09G [00:49<00:03, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  94%|█████████▍| 1.97G/2.09G [00:49<00:03, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  95%|█████████▌| 1.99G/2.09G [00:49<00:02, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  96%|█████████▌| 2.00G/2.09G [00:50<00:02, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  96%|█████████▋| 2.01G/2.09G [00:50<00:01, 40.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  97%|█████████▋| 2.02G/2.09G [00:51<00:02, 30.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  97%|█████████▋| 2.03G/2.09G [00:51<00:01, 34.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  98%|█████████▊| 2.04G/2.09G [00:51<00:01, 27.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  98%|█████████▊| 2.06G/2.09G [00:52<00:01, 27.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  99%|█████████▉| 2.07G/2.09G [00:52<00:00, 30.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin:  99%|█████████▉| 2.08G/2.09G [00:53<00:00, 20.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin: 100%|█████████▉| 2.09G/2.09G [00:53<00:00, 24.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.09G/2.09G [00:53<00:00, 38.9MB/s]\u001b[A\u001b[A\n",
      "Downloading pytorch_model.bin:   5%|▍         | 94.4M/2.09G [01:34<33:23, 997kB/s] \n"
     ]
    }
   ],
   "source": [
    "model_1B = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-1B-deduped\",\n",
    "    revision=\"step3000\",\n",
    "    device_map=\"auto\",\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 1234.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataset(\n",
    "    \"pile_val\",\n",
    "    tokenizer,\n",
    "    10,\n",
    "    60,\n",
    "    suffix_length=1,\n",
    "    num_buffer=0,\n",
    "    suffix_batch_size=1,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m, data_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/val.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(num_examples))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "num_examples = 20\n",
    "dataset = load_dataset('json', data_files='data/val.jsonl')\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset['train'].select(range(num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"\\n    pageEncoding=\"UTF-8\"%>\\n<%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %>\\n<%@ taglib uri=\"http://www.springframework.org/security/tags\" prefix=\"sec\" %>\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\\n<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\\n<title>Home Page</title>\\n</head>\\n<body>\\n<h3>Home Page</h3>\\n\\n\\t<p>\\n      Hello <b><c:out value=\"${pageContext.request.remoteUser}\"/></b><br>\\n      Roles: <b><sec:authentication property=\"principal.authorities\" /></b>\\n    </p>\\n    \\n    <form action=\"logout\" method=\"post\">\\n      <input type=\"submit\" value=\"Logout\" />\\n      <input type=\"hidden\" name=\"${_csrf.parameterName}\" value=\"${_csrf.token}\"/>\\n    </form>\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrogens interact in a variety of ways with the liver. Not only is the liver an estrogen-responsive tissue, but it is also responsible for the interconversion, metabolism and excretion of the estrogens. The effect of liver disease on these processes has not been studied well, except in the specific case\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "Rainbow (ride)\n",
      "\n",
      "Rainbow is the name of the amusement park ride created by HUSS Maschinenfabrik of Bremen, Germany which is now HUSS Park Attractions of Budapest, Hungary. The Rainbow was manufactured from 1983-2000 and is often confused with its cousins\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "[Biological bases of ventricular remodeling].\n",
      "Cardiac hypertrophy commonly observed in clinical practice is not a disease but a physiological reaction to disease, usually hypertensive or coronary. It involves changes in gene expression, often species specific, which account for the thermodynamic adaptation of the cardiac muscle to new conditions of load;\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "Sunday, November 06, 2011\n",
      "\n",
      "lazy Sunday\n",
      "\n",
      "\"Falling back\" has led to a day of perfect relaxation. I started off my lazy Sunday by casting off a puerperium cardigan (pictures soon!), then meeting friends for brunch at Milk & Honey Cafe,\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "Geghamabak\n",
      "\n",
      "Geghamabak (; formerly, Kayabash, Ghayabagh, and Quşabulaq) is a small village in the Gegharkunik Province of Armenia.\n",
      "\n",
      "See also \n",
      "Gegharkunik\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "<%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"\n",
      "    pageEncoding=\"UTF-8\"%>\n",
      "<%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %>\n",
      "\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "Embattled DR Congo opposition leader Moise Katumbi, who last month quit the country ostensibly for medical treatment, was sentenced to three years in jail Wednesday over a real estate dispute.\n",
      "\n",
      "Katumbi, a football magnate, was seen as the leading challenger to President Joseph\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "import subprocess\n",
      "\n",
      "\n",
      "def installCertBot():\n",
      "    cmd = []\n",
      "\n",
      "    cmd.append(\"yum\")\n",
      "    cmd.append(\"-y\")\n",
      "    cmd.append(\"install\")\n",
      "    cmd.append(\"certbot\")\n",
      "\n",
      "    res = subprocess.call(cmd\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "<?php\n",
      "abstract class HelpdeskService implements RemoteService {\n",
      "\t\n",
      "\tpublic abstract function getDate();\n",
      "\t\n",
      "\tpublic abstract function getAppData();\n",
      "\t\n",
      "\tpublic abstract function getMessage($msg);\n",
      "\t\n",
      "\tpublic abstract function getEnquiryById($id);\n",
      "\t\n",
      "\tpublic abstract function getEnqu\n",
      "\\\\\\\\\\\\\\\\\\\n",
      "Carmarthen Bank\n",
      "\n",
      "Carmarthen Bank was a bank established and formerly operated in the  county of Carmarthenshire, Wales during the 19th century. It became bankrupt in 1832 and its name was then adopted by another Carmarthenshire-based bank.\n",
      "\n",
      "\\\\\\\\\\\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(tokenizer.decode(batch.input_ids[0]))\n",
    "    print(\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_length = 10\n",
    "suffix = \" Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "# tokenized_suffix = tokenized_suffix.unsqueeze(0)\n",
    "suffix_length = len(tokenized_suffix[0])\n",
    "empirical_dist = torch.load(\"..\\data\\pythia-160m-deduped-v0_stationary_dist.pt\").cuda()\n",
    "\n",
    "vocab_size = empirical_dist.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:18<00:00, 21.33it/s]\n",
      "100%|██████████| 393/393 [00:20<00:00, 19.16it/s]\n",
      "100%|██████████| 393/393 [00:27<00:00, 14.46it/s]\n",
      "100%|██████████| 393/393 [00:32<00:00, 12.13it/s]\n",
      "100%|██████████| 393/393 [00:36<00:00, 10.82it/s]\n",
      "100%|██████████| 393/393 [00:41<00:00,  9.38it/s]\n",
      "100%|██████████| 393/393 [00:45<00:00,  8.64it/s]\n",
      "100%|██████████| 393/393 [00:33<00:00, 11.67it/s]\n",
      "100%|██████████| 393/393 [00:34<00:00, 11.53it/s]\n",
      "100%|██████████| 393/393 [01:04<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import sample_reverse_dynamics_reverse_prior\n",
    "\n",
    "output1, logits1 = sample_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    prefix_length,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = torch.load(\"../data/distributions/probs_10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e-16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors[priors==0] = 1e-16\n",
    "priors = priors/priors.sum(dim=0)\n",
    "torch.min(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:05<00:00, 68.60it/s]\n",
      "100%|██████████| 393/393 [00:06<00:00, 61.18it/s]\n",
      "100%|██████████| 393/393 [00:07<00:00, 51.69it/s]\n",
      "100%|██████████| 393/393 [00:09<00:00, 43.36it/s]\n",
      "100%|██████████| 393/393 [00:09<00:00, 39.93it/s]\n",
      "100%|██████████| 393/393 [00:11<00:00, 35.14it/s]\n",
      "100%|██████████| 393/393 [00:12<00:00, 32.44it/s]\n",
      "100%|██████████| 393/393 [00:13<00:00, 28.79it/s]\n",
      "100%|██████████| 393/393 [00:14<00:00, 26.35it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 24.39it/s]\n"
     ]
    }
   ],
   "source": [
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = rs.compute_loss_reverse_dynamics(\n",
    "    model,\n",
    "    priors,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.131247520446777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'reverse_sampling' from '/home/adi224/reverse-dynamics-nlp/reverse-llm-benchmarking/reverse_sampling.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import reverse_sampling as rs\n",
    "reload(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.13it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  6.93it/s]\n",
      "100%|██████████| 26/26 [00:04<00:00,  5.20it/s]\n",
      "100%|██████████| 26/26 [00:06<00:00,  4.12it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:08<00:00,  2.91it/s]\n",
      "100%|██████████| 26/26 [00:10<00:00,  2.60it/s]\n",
      "100%|██████████| 26/26 [00:11<00:00,  2.29it/s]\n",
      "100%|██████████| 26/26 [00:13<00:00,  2.00it/s]\n",
      "100%|██████████| 26/26 [00:14<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.108232021331787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "suffix = \" Hi, my name is Alex. What's up?\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = rs.compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=2000,\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:16<00:00,  5.98it/s]\n",
      "100%|██████████| 101/101 [00:24<00:00,  4.12it/s]\n",
      "100%|██████████| 101/101 [00:33<00:00,  3.00it/s]\n",
      "100%|██████████| 101/101 [00:41<00:00,  2.44it/s]\n",
      "100%|██████████| 101/101 [00:50<00:00,  2.02it/s]\n",
      "100%|██████████| 101/101 [00:58<00:00,  1.73it/s]\n",
      "100%|██████████| 101/101 [01:07<00:00,  1.49it/s]\n",
      "100%|██████████| 101/101 [01:13<00:00,  1.37it/s]\n",
      "100%|██████████| 101/101 [01:22<00:00,  1.23it/s]\n",
      "100%|██████████| 101/101 [01:29<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.162289619445801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_1B = rs.compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model_1B,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=500,\n",
    ")\n",
    "print(loss_1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \" Hi, my name is Alex. What's up?\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = rs.compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=2000,\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7155, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reversed_suffix = torch.flip(tokenized_suffix, dims=[1])\n",
    "\n",
    "reverse_model.eval()\n",
    "reverse_logits = reverse_model(reversed_suffix[:,:-1]).logits\n",
    "reverse_loss = torch.nn.CrossEntropyLoss()(reverse_logits[0,:,:], reversed_suffix[0, 1:])\n",
    "print(reverse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8015, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "forward_logits = model(tokenized_suffix[:,:-1]).logits\n",
    "forward_loss = torch.nn.CrossEntropyLoss()(forward_logits[0,:,:], tokenized_suffix[0, 1:])\n",
    "print(forward_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.780669689178467"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:06<00:00, 63.79it/s]\n",
      "100%|██████████| 393/393 [00:06<00:00, 58.02it/s]\n",
      "100%|██████████| 393/393 [00:07<00:00, 49.29it/s]\n",
      "100%|██████████| 393/393 [00:09<00:00, 41.78it/s]\n",
      "100%|██████████| 393/393 [00:10<00:00, 38.85it/s]\n",
      "100%|██████████| 393/393 [00:11<00:00, 34.12it/s]\n",
      "100%|██████████| 393/393 [00:12<00:00, 31.49it/s]\n",
      "100%|██████████| 393/393 [00:13<00:00, 28.16it/s]\n",
      "100%|██████████| 393/393 [00:15<00:00, 25.84it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import compute_loss_reverse_dynamics_reverse_prior\n",
    "\n",
    "\n",
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = compute_loss_reverse_dynamics_reverse_prior(\n",
    "    model,\n",
    "    reverse_model,\n",
    "    tokenized_suffix,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440132141113281\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3918, 10053,  3778,  4724,   247, 15091,  1411,  3438,  3918, 22306,\n",
       "          6729]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing loss:   0%|          | 0/1 [00:00<?, ?it/s]You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3918, 10053,  3778,  4724,   247, 15091,  1411,  3438,  3918, 22306,\n",
      "          6729]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:01,  4.87it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:01,  3.80it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:00<00:01,  3.52it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:01,  3.40it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:01<00:00,  3.33it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:01<00:00,  3.30it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:02<00:00,  3.28it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.37it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:02,  2.56it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  2.37it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:01,  2.29it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  2.25it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:02<00:00,  2.22it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:03<00:00,  2.20it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:02,  2.46it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.91it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  1.77it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.71it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  1.68it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:03<00:01,  1.66it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:04<00:00,  1.65it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  1.95it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.51it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:03,  1.40it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.36it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.33it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.32it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.31it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.35it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:08,  1.20s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:05,  1.13it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.11it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.10it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.09it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:05<00:01,  1.09it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:06<00:00,  1.09it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:04,  1.41it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:05,  1.10it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.02it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:03<00:04,  1.02s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:03,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:06<00:02,  1.05s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:07<00:01,  1.06s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:08<00:00,  1.03s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:10,  1.44s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:02<00:07,  1.28s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:03<00:06,  1.26s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:05<00:04,  1.25s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:06<00:03,  1.24s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:07<00:02,  1.24s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:08<00:01,  1.24s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:10,  1.46s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:02<00:08,  1.38s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:04<00:06,  1.39s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:05<00:05,  1.40s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:07<00:04,  1.40s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:08<00:02,  1.40s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:09<00:01,  1.41s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:11<00:00,  1.41s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:11,  1.62s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:03<00:09,  1.54s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:04<00:07,  1.55s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:06<00:06,  1.56s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:07<00:04,  1.56s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:09<00:03,  1.57s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:10<00:01,  1.57s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:12<00:00,  1.57s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:02<00:17,  2.53s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:03<00:10,  1.77s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:05<00:08,  1.76s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:07<00:07,  1.76s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:09<00:05,  1.75s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:10<00:03,  1.76s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:12<00:01,  1.76s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:14<00:00,  1.79s/it]\u001b[A\n",
      "Computing loss: 100%|██████████| 1/1 [01:23<00:00, 83.94s/it]\n"
     ]
    }
   ],
   "source": [
    "%run stationary_reversal_loss.py --num_examples 1 --vocab_batch_size 6288 --reverse_model_prior true --prefix_length 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverse_sampling import compute_loss_reverse_dynamics\n",
    "\n",
    "suffix = \" President Donald Trump filed a lawsuit against former President Barack Obama\"\n",
    "tokenized_suffix= tokenizer.encode(suffix, return_tensors=\"pt\").to(device)\n",
    "\n",
    "loss = compute_loss_reverse_dynamics(\n",
    "    model,\n",
    "    empirical_dist,\n",
    "    tokenized_suffix,\n",
    "    dilution=1.0,\n",
    "    vocab_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dateset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Posterior vs Stationary Reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_dist = torch.ones_like(empirical_dist) / empirical_dist.shape[0]\n",
    "empirical_dist = empirical_dist * 0.7 + uniform_dist * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:13<00:00,  7.47it/s]\n",
      "100%|██████████| 99/99 [00:14<00:00,  7.02it/s]\n",
      "100%|██████████| 99/99 [00:17<00:00,  5.76it/s]\n",
      "100%|██████████| 99/99 [00:18<00:00,  5.39it/s]\n",
      "100%|██████████| 99/99 [00:24<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from reverse_sampling import sample_reverse_dynamics\n",
    "\n",
    "output1, logits1 = sample_reverse_dynamics(\n",
    "    model,\n",
    "    empirical_dist,\n",
    "    prefix_length,\n",
    "    tokenized_suffix,\n",
    "    temperature=0.7,\n",
    "    vocab_batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In thiserior pair, Obama'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "logits2 = sr.stationary_reverse_full_dist_suffix_calculation(model, empirical_dist, output1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-14.1750, -14.4474, -15.0450,  ..., -13.0240, -12.8964, -13.3337],\n",
       "        [-12.3171, -12.7534, -13.0377,  ..., -12.1253,  -9.1679, -14.2333],\n",
       "        [-13.4286, -12.3321, -11.0569,  ..., -10.6190, -11.5005, -12.7546],\n",
       "        [-11.3032, -11.4353, -13.2914,  ..., -12.1252, -11.5411, -13.5619],\n",
       "        [-13.5377, -15.0662,  -8.3655,  ..., -14.6411, -13.6813, -13.2714]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits1.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0518e-05, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(logits2 - logits1.log_softmax(dim=-1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Step 1: Create an empty list to hold all JSON objects.\n",
    "all_data = []\n",
    "\n",
    "# Step 2: Loop through each JSON file in the directory where your files are stored.\n",
    "for filename in glob.glob('data/pile_val/*.json'):\n",
    "    with open(filename, 'r') as file:\n",
    "        # Read the single line of JSON and parse it.\n",
    "        json_data = json.loads(file.readline())\n",
    "        # Append the dictionary to the list.\n",
    "        all_data.append(json_data)\n",
    "\n",
    "# Step 3: Write the list of dictionaries to a new JSON file.\n",
    "with open('combined_data.json', 'w') as outfile:\n",
    "    json.dump(all_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mean': 5.902055968046188,\n",
       "  'variance': 2.9243932490525784,\n",
       "  'std_on_mean': 0.17100857431873345,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.2},\n",
       " {'mean': 3.7944451820850373,\n",
       "  'variance': 1.3930675834793667,\n",
       "  'std_on_mean': 0.11802828404578991,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 5.567424488067627,\n",
       "  'variance': 2.3046989259260138,\n",
       "  'std_on_mean': 0.48007279926340474,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '410m'},\n",
       " {'mean': 5.881934969425202,\n",
       "  'variance': 1.3117366918483122,\n",
       "  'std_on_mean': 0.11453107403007763,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 10,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 6.125863807201386,\n",
       "  'variance': 2.801961312589026,\n",
       "  'std_on_mean': 0.16739060047054694,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.4,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.921818646192551,\n",
       "  'variance': 2.9528719554662475,\n",
       "  'std_on_mean': 0.1718392258905471,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.2},\n",
       " {'mean': 7.409825747013092,\n",
       "  'variance': 3.1201337286434265,\n",
       "  'std_on_mean': 0.17663900273278907,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/smoothed_probs_10.pt',\n",
       "  'dilution': 0.4,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 5.8470072746276855,\n",
       "  'variance': 1.3201813358728953,\n",
       "  'std_on_mean': 0.11489914429067324,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 10,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 4.68057701587677,\n",
       "  'variance': 1.8708533668834602,\n",
       "  'std_on_mean': 0.4325336249222088,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'device': 'cuda',\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.953478407859802,\n",
       "  'variance': 2.245164438493409,\n",
       "  'std_on_mean': 0.14983872792083525,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 20,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 5.987042251825333,\n",
       "  'variance': 2.863637291320495,\n",
       "  'std_on_mean': 0.16922284985546412,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.4},\n",
       " {'mean': 5.870876908302307,\n",
       "  'variance': 2.0224048625667734,\n",
       "  'std_on_mean': 0.4497115589538224,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.7,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 6.376853818893433,\n",
       "  'variance': 2.706090528548768,\n",
       "  'std_on_mean': 0.1645019917371449,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.2,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.905772322416306,\n",
       "  'variance': 3.0646604159031265,\n",
       "  'std_on_mean': 0.17506171528644196,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 1.0,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.46494608104229,\n",
       "  'variance': 3.8171891995005636,\n",
       "  'std_on_mean': 0.19537628309241026,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.2,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 2.829386532180011,\n",
       "  'variance': 0.8332415371077588,\n",
       "  'std_on_mean': 0.028865923458426875,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 8.03367482662201,\n",
       "  'variance': 1.9618762068543893,\n",
       "  'std_on_mean': 0.14006699135964867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.905772310495377,\n",
       "  'variance': 3.064660453937176,\n",
       "  'std_on_mean': 0.17506171637274598,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 6.395029375553131,\n",
       "  'variance': 2.729653022433814,\n",
       "  'std_on_mean': 0.16521661606611526,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.2,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.431550749838352,\n",
       "  'variance': 3.427383108671701,\n",
       "  'std_on_mean': 0.1851319288688934,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.2,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 5.5422512179613115,\n",
       "  'variance': 3.3802772878781746,\n",
       "  'std_on_mean': 0.18385530418995735,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.4,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 3.0134240704774857,\n",
       "  'variance': 0.816403671182231,\n",
       "  'std_on_mean': 0.09035505913794926,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 2.6161921471357346,\n",
       "  'variance': 0.7757284637416746,\n",
       "  'std_on_mean': 0.0880754485507553,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 8.033674807548524,\n",
       "  'variance': 1.9618761721335463,\n",
       "  'std_on_mean': 0.14006699012021162,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 1.0},\n",
       " {'mean': 3.2168437704145907,\n",
       "  'variance': 0.8049592230600622,\n",
       "  'std_on_mean': 0.02837180330997771,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000},\n",
       " {'mean': 5.96704402923584,\n",
       "  'variance': 2.3225680815739924,\n",
       "  'std_on_mean': 0.15239974020889907,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 20,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 3.130835123077035,\n",
       "  'variance': 0.8737931690029227,\n",
       "  'std_on_mean': 0.029559992709791434,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 6.144345463514328,\n",
       "  'variance': 2.826969204275754,\n",
       "  'std_on_mean': 0.16813593322891315,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.4,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 8.03367482662201,\n",
       "  'variance': 1.9618762068543893,\n",
       "  'std_on_mean': 0.14006699135964867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.403787612915039,\n",
       "  'variance': 0.030588694848120213,\n",
       "  'std_on_mean': 0.12367031747375805,\n",
       "  'nbatches': 2,\n",
       "  'num_examples': 2,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 262,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.0,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 4.217538380622864,\n",
       "  'variance': 1.5683602068174818,\n",
       "  'std_on_mean': 0.3960252778317922,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'device': 'cuda',\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 2.3592866617441177,\n",
       "  'variance': 0.7557623486585087,\n",
       "  'std_on_mean': 0.08693459315246772,\n",
       "  'total_samples': 100,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 100,\n",
       "  'sample_length': 2048},\n",
       " {'mean': 3.648958516120911,\n",
       "  'variance': 1.3038870586557783,\n",
       "  'std_on_mean': 0.3610937632604277,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'device': 'cuda',\n",
       "  'reverse_model_prior': False,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 3.216844655483961,\n",
       "  'variance': 0.8049589379035442,\n",
       "  'std_on_mean': 0.02837179828462666,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 5.923955225944519,\n",
       "  'variance': 2.007545950700597,\n",
       "  'std_on_mean': 0.4480564641538605,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 5.3657335215806965,\n",
       "  'variance': 3.5412856185113912,\n",
       "  'std_on_mean': 0.1881830390473964,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/probs_10.pt',\n",
       "  'dilution': 0.0,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 6.005882073640823,\n",
       "  'variance': 2.889953721230947,\n",
       "  'std_on_mean': 0.16999863885428457,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pythia-160m-deduped-v0_stationary_dist.pt',\n",
       "  'dilution': 0.4},\n",
       " {'mean': 8.130361356735229,\n",
       "  'variance': 4.879760712015729,\n",
       "  'std_on_mean': 0.2209018042483069,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/smoothed_probs_10.pt',\n",
       "  'dilution': 0.0,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 3.5711511905044317,\n",
       "  'variance': 0.9340061170230513,\n",
       "  'std_on_mean': 0.03056151365726265,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000},\n",
       " {'mean': 5.8470072746276855,\n",
       "  'variance': 1.3201813358728953,\n",
       "  'std_on_mean': 0.11489914429067324,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 10,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 8.03367482662201,\n",
       "  'variance': 1.9618762068543893,\n",
       "  'std_on_mean': 0.14006699135964867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 8.155158948898315,\n",
       "  'variance': 0.4123599850644246,\n",
       "  'std_on_mean': 0.20306648789606435,\n",
       "  'nbatches': 10,\n",
       "  'num_examples': 10,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 1.0,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 7.525179170370102,\n",
       "  'variance': 3.516449845944826,\n",
       "  'std_on_mean': 0.18752199460182867,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/smoothed_probs_10.pt',\n",
       "  'dilution': 0.2,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 9},\n",
       " {'mean': 5.883956278562546,\n",
       "  'variance': 3.038872731345512,\n",
       "  'std_on_mean': 0.17432362809858887,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 12576,\n",
       "  'device': 'cuda',\n",
       "  'dist': '../data/distributions/pile10k_empirical.pt',\n",
       "  'dilution': 0.0},\n",
       " {'mean': 3.571150739625096,\n",
       "  'variance': 0.9340061847834702,\n",
       "  'std_on_mean': 0.030561514765853316,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000,\n",
       "  'sample_length': 50},\n",
       " {'mean': 5.454675911068916,\n",
       "  'variance': 3.979176864335709,\n",
       "  'std_on_mean': 0.19947874233450816,\n",
       "  'nbatches': 100,\n",
       "  'num_examples': 100,\n",
       "  'prefix_length': 10,\n",
       "  'suffix_length': 1,\n",
       "  'num_buffer': 0,\n",
       "  'suffix_batch_size': 1,\n",
       "  'vocab_batch_size': 6288,\n",
       "  'device': 'cuda',\n",
       "  'dist': None,\n",
       "  'dilution': 0.4,\n",
       "  'reverse_model_prior': True,\n",
       "  'multiple_priors_start_idx': 0,\n",
       "  'multiple_priors_end_idx': 0,\n",
       "  'model_size': '160m'},\n",
       " {'mean': 2.829386526942253,\n",
       "  'variance': 0.8332412405481479,\n",
       "  'std_on_mean': 0.028865918321580347,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000},\n",
       " {'mean': 3.130835074454546,\n",
       "  'variance': 0.8737934575557981,\n",
       "  'std_on_mean': 0.02955999759059189,\n",
       "  'total_samples': 1000,\n",
       "  'batch_size': 1,\n",
       "  'nbatches': 1000}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
