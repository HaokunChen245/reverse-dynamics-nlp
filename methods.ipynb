{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from src import *\n",
    "\n",
    "\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"EleutherAI/pythia-160m-deduped\",\n",
    ").cuda()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-1.4b-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-160m-deduped/step3000\",\n",
    "  device_map=\"auto\"\n",
    ")\n",
    "\n",
    "reverse_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"afterless/reverse-pythia-160m\"\n",
    ").cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", that it is up to him, that it is up to him, that it is up to him, and that he\n",
      " should never be president\n"
     ]
    }
   ],
   "source": [
    "input_str = rand_init(25, tokenizer)\n",
    "expected_output = \" should never be president\"\n",
    "\n",
    "# Reinitialize string to be a sample from RLM\n",
    "rlm = ReverseModelSampler(model, reverse_model, tokenizer, num_beams=1)\n",
    "input_str = rlm.optimize(input_str, expected_output, temperature=0.01).split(expected_output)[0]\n",
    "\n",
    "print(input_str.replace(\"\\n\", \"\"))\n",
    "print(expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCG based methods\n",
    "gcg = GreedyCoordinateGradient(model, tokenizer, n_top_indices=128, n_proposals=1024, n_epochs=512, prefix_loss_weight=-1)\n",
    "gcg_reg = GreedyCoordinateGradient(model, tokenizer, n_top_indices=128, n_proposals=1024, n_epochs=512,  prefix_loss_weight=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCG:  someday”— itбysipolar Justice, that94 powers Chad McCain six, that it is horrific to him alleged spends arguing he should never be president\n",
      "GCG Reg: , that it is up to Obama, that it is up to him, that it is up Sadly him, and that he should never be president\n"
     ]
    }
   ],
   "source": [
    "output1 = gcg.optimize(input_str, expected_output)\n",
    "print(\"GCG:\", output1.replace(\"\\n\", \"\"))\n",
    "output2 = gcg_reg.optimize(input_str, expected_output)\n",
    "print(\"GCG Reg:\", output2.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.88it/s]\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.48it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.77it/s]\n",
      "100%|██████████| 50/50 [00:20<00:00,  2.41it/s]\n",
      "100%|██████████| 50/50 [00:25<00:00,  1.93it/s]\n",
      "100%|██████████| 50/50 [00:27<00:00,  1.83it/s]\n",
      "100%|██████████| 50/50 [00:30<00:00,  1.64it/s]\n",
      "100%|██████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|██████████| 50/50 [00:35<00:00,  1.40it/s]\n",
      "100%|██████████| 50/50 [00:39<00:00,  1.28it/s]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "100%|██████████| 50/50 [00:46<00:00,  1.07it/s]\n",
      "100%|██████████| 50/50 [00:49<00:00,  1.01it/s]\n",
      "100%|██████████| 50/50 [00:55<00:00,  1.11s/it]\n",
      "100%|██████████| 50/50 [00:57<00:00,  1.16s/it]\n",
      "100%|██████████| 50/50 [01:01<00:00,  1.22s/it]\n",
      "100%|██████████| 50/50 [01:03<00:00,  1.27s/it]\n",
      "100%|██████████| 50/50 [01:07<00:00,  1.36s/it]\n",
      "100%|██████████| 50/50 [01:09<00:00,  1.40s/it]\n",
      "100%|██████████| 50/50 [01:17<00:00,  1.54s/it]\n",
      "100%|██████████| 50/50 [01:17<00:00,  1.55s/it]\n",
      "100%|██████████| 50/50 [01:17<00:00,  1.55s/it]\n",
      "100%|██████████| 50/50 [01:20<00:00,  1.60s/it]\n",
      "100%|██████████| 50/50 [01:26<00:00,  1.74s/it]\n",
      "100%|██████████| 50/50 [01:26<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Reversal:  do this, it is here, this is a part of a lot of things in the world. I believe that Donald Trump should never be president\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dist = torch.load(\"data/distributions/pile_empirical.pt\")\n",
    "bayes = ReversalEmpiricalPrior(model, dist, tokenizer)\n",
    "output3 = bayes.optimize(input_str, expected_output, temperature=0.7)\n",
    "print(\"Bayesian Reversal:\", output3.replace(\"\\n\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLM Sampler:  with his handling of the presidency of Donald Trump.\"He should never be president of the United States and Mr Clinton should never be president\n"
     ]
    }
   ],
   "source": [
    "rlm = ReverseModelSampler(model, reverse_model, tokenizer, num_beams=1000)\n",
    "output4 = rlm.optimize(input_str, expected_output, temperature=1)\n",
    "print(\"RLM Sampler:\", output4.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix:  should never be president\n",
      "GCG Output:   someday”— itбysipolar Justice, that94 powers Chad McCain six, that it is horrific to him alleged spends arguing he should never be president\n",
      "GCG Reg Output:  , that it is up to Obama, that it is up to him, that it is up Sadly him, and that he should never be president\n",
      "Bayesian Reversal Output:  do this, it is here, this is a part of a lot of things in the world. I believe that Donald Trump should never be president\n",
      "Reverse LM Output: .If that is not true then you should never be president.If that is not true, then you should never be president\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Suffix:\", expected_output)\n",
    "print(\"GCG Output: \", output1.replace(\"\\n\", \"\"))\n",
    "print(\"GCG Reg Output: \", output2.replace(\"\\n\", \"\"))\n",
    "print(\"Bayesian Reversal Output:\", output3.replace(\"\\n\", \"\"))\n",
    "print(\"Reverse LM Output:\", output4.replace(\"\\n\", \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
